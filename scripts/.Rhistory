hist(table(trialdata$spelling)) # Three values: 39, 40, 41
hist(table(trialdata$spelling)) # Three values: 39, 40, 41
view(hist(table(trialdata$spelling))) # Three values: 39, 40, 41
View(hist(table(trialdata$spelling))) # Three values: 39, 40, 41
print(hist(table(trialdata$spelling))) # Three values: 39, 40, 41
spelling <- as.data.frame(table(trialdata$spelling))
View(spelling)
View(trialdata)
# Clean up the trial dataset, make sure RT and Accuracy values are intact
trialdata <- distinct(trialdata)
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Import the CSV with assigned diminutive values
dim_data <- read_csv("../corpus/dims_assigned.csv")
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset, make sure RT and Accuracy values are intact
trialdata <- distinct(trialdata)
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
trialdata <- filter(trialdata, complete.cases(trialdata$corrn))
# Check the intended against the actual number of observations
table(trialdata$nobs) # Two values: 40 or 41
table(trialdata$spelling)
hist(table(trialdata$spelling)) # Three values: 39, 40, 41
spelling <- as.data.frame(table(trialdata$spelling))
View(spelling)
# Remove all trials with error responses
trialdata <- filter(trialdata, is_error==1, corrn=1)
# Remove all trials with error responses
trialdata <- filter(trialdata, is_error==1, corrn==1)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset, make sure RT values are intact
trialdata <- distinct(trialdata)
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials with error responses
trialdata <- filter(trialdata, is_error==1)
View(trialdata)
# Remove all trials with error responses: leave only real words recognized as such
trialdata <- filter(trialdata, is_error==0)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset, make sure RT values are intact
trialdata <- distinct(trialdata)
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials with error responses: leave only real words recognized as such
trialdata <- filter(trialdata, is_error==0)
View(trialdata)
trialdata <- filter(trialdata, acc.mean>=0.65)
View(trialdata)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials f
trialdata <- filter(trialdata, acc.mean>=0.65)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials with error responses
trialdata <- filter(trialdata, is_error==0)
# Remove all trials f
trialdata <- filter(trialdata, acc.mean>=0.65)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==1)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtR))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==0)
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtC))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==0)
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtC))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==0)
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==0)
View(trialdata)
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
library(dplyr)
library(lme4)
library(car)
library(readr)
library(ggplot2)
# Variables and Items for predictor data
variables <- read_csv("../corpus/dlp2_variables.csv")
items <- read_tsv("../corpus/dlp2_items.tsv")
# Make a big table for all items and variables
data <- inner_join(items, variables, by="spelling")
# Exclude nonwords, filter for only nouns
data <- filter(data, lexicality=="W", PoS=="N")
# Trials for participant response data
t0 <- read_tsv("../corpus/dlp2_trials0.tsv")
t1 <- read_tsv("../corpus/dlp2_trials1.tsv")
trials <- rbind(t0, t1)
# Filter the trials block to exclude repeating trial blocks (0-1 = 60-61)
# Remove the first two blocks for RT modelling to account for learning effects
trials <- filter(trials, block >= 2)
# Variables and Items for predictor data
variables <- read_csv("../corpus/dlp2_variables.csv", show_col_types = FALSE)
items <- read_tsv("../corpus/dlp2_items.tsv", show_col_types = FALSE)
# Make a big table for all items and variables
data <- inner_join(items, variables, by="spelling")
# Exclude nonwords, filter for only nouns
data <- filter(data, lexicality=="W", PoS=="N")
# Trials for participant response data
t0 <- read_tsv("../corpus/dlp2_trials0.tsv", show_col_types = FALSE)
t1 <- read_tsv("../corpus/dlp2_trials1.tsv", show_col_types = FALSE)
t1 <- read_tsv("../corpus/dlp2_trials1.tsv", show_col_types = FALSE)
trials <- rbind(t0, t1)
trials <- rbind(t0, t1)
# Filter the trials block to exclude repeating trial blocks (0-1 = 60-61)
# Remove the first two blocks for RT modelling to account for learning effects
trials <- filter(trials, block >= 2)
# Set up a value for diminutive type
data$dim_type = "none"
# Assign "undecided" to any wordform ending with "-je"
data[grepl(".+je$", data$spelling),]$dim_type <- "undecided"
# Use the "undecided" value to filter for only diminutives
diminutives <- filter(data, dim_type=="undecided") # 364 in total
# Set up a few values for manual assignment
diminutives$Nmorph <- 0
diminutives$double_checked <- 0
diminutives$notes <- "unassigned"
# Select only the relevant values to keep the assignment CSV readable
diminutives <- select(diminutives, c(spelling,
dim_type,
Nmorph,
double_checked,
notes))
# Write the CSV for manual assignment
write_csv(diminutives, file="../corpus/dims_unass.csv")
print("Done!")
# Remove dim_type from the noun dataset to avoid duplicates post-merge
data <- select(data, -"dim_type")
# Import the CSV with assigned diminutive values
dim_data <- read_csv("../corpus/dims_assigned.csv")
# Import the CSV with assigned diminutive values
dim_data <- read_csv("../corpus/dims_assigned.csv", show_col_types = FALSE)
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtC))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.65, is_error==0)
View(trialdata)
# Filter out the irrelevant variables
trialdata1 <- select(trialdata,
-"item.x",
-"lexicality.x",
-"nobs")
# Filter out the irrelevant variables
trialdata1 <- select(trialdata,
-"item.x",
-"lexicality.x", # Single-value column
-"nobs",
-"acc.mean", # Duplicated in column "Acc_dlp2"
-"acc.sd",
-"rtC.mean", # Duplicated in column "RT_dlp2"
-"rtC.sd",
-"rateC.mean",
-"rateC.sd",
-"zrtC.mean",
-"zrtC.sd",
-"zrateC.mean",
-"zrateC.sd",
-"rtl.mean",
-"rtl.sd",
-"ratel.mean",
-"ratel.sd",
-"zrtl.mean",
-"zrtl.sd",
-"zratel.mean",
-"zratel.sd",
-"PoS", # Single-value column
-"Colt_N", # OLD20 chosen as neighbourhood predictor
-"PLD30", # OLD20 chosen as neighbourhood predictor
-"Colt_Nphon",
-"list",
-"block",
-"subblock",
-"trial_in_block",
-"trial_in_subblock",
-"trial",
-"observation",
-"warmup", # Single-value column
-"repetition",
-"item.y",
-"pair",
-"lexicality.y", # Single-value column
-"handedness",
-"xrb",
-"one", # Single-value column
-"rb",
-"r", # Single-value column
-"corr", # Single-value column
-"corrn", # Single-value column
-"is_missing", # Single-value column
-"is_error", # Single-value column
-"is_bad_item",
-"is_lt_200", # Single-value column
-"is_gt_1999", # Single-value column
-"is_lt_lower", # Single-value column
-"is_gt_upper", # Single-value column
-"is_imputed", # Single-value column
)
# Filter out the irrelevant variables
trialdata1 <- select(trialdata,
-"item.x",
-"lexicality.x", # Single-value column
-"nobs",
-"acc.mean", # Duplicated in column "Acc_dlp2"
-"acc.sd",
-"rtC.mean", # Duplicated in column "RT_dlp2"
-"rtC.sd",
-"rateC.mean",
-"rateC.sd",
-"zrtC.mean",
-"zrtC.sd",
-"zrateC.mean",
-"zrateC.sd",
-"rtI.mean",
-"rtI.sd",
-"rateI.mean",
-"rateI.sd",
-"zrtI.mean",
-"zrtI.sd",
-"zrateI.mean",
-"zrateI.sd",
-"PoS", # Single-value column
-"Colt_N", # OLD20 chosen as neighbourhood predictor
-"PLD30", # OLD20 chosen as neighbourhood predictor
-"Colt_Nphon",
-"list",
-"block",
-"subblock",
-"trial_in_block",
-"trial_in_subblock",
-"trial",
-"observation",
-"warmup", # Single-value column
-"repetition",
-"item.y",
-"pair",
-"lexicality.y", # Single-value column
-"handedness",
-"xrb",
-"one", # Single-value column
-"rb",
-"r", # Single-value column
-"corr", # Single-value column
-"corrn", # Single-value column
-"is_missing", # Single-value column
-"is_error", # Single-value column
-"is_bad_item",
-"is_lt_200", # Single-value column
-"is_gt_1999", # Single-value column
-"is_lt_lower", # Single-value column
-"is_gt_upper", # Single-value column
-"is_imputed", # Single-value column
)
View(trialdata1)
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.66, is_error==0)
# Filter out the irrelevant variables
trialdata1 <- select(trialdata,
-"item.x",
-"lexicality.x", # Single-value column
-"nobs",
-"acc.mean", # Duplicated in column "Acc_dlp2"
-"acc.sd",
-"rtC.mean", # Duplicated in column "RT_dlp2"
-"rtC.sd",
-"rateC.mean",
-"rateC.sd",
-"zrtC.mean",
-"zrtC.sd",
-"zrateC.mean",
-"zrateC.sd",
-"rtI.mean",
-"rtI.sd",
-"rateI.mean",
-"rateI.sd",
-"zrtI.mean",
-"zrtI.sd",
-"zrateI.mean",
-"zrateI.sd",
-"PoS", # Single-value column
-"Colt_N", # OLD20 chosen as neighbourhood predictor
-"PLD30", # OLD20 chosen as neighbourhood predictor
-"Colt_Nphon",
-"list",
-"block",
-"subblock",
-"trial_in_block",
-"trial_in_subblock",
-"trial",
-"observation",
-"warmup", # Single-value column
-"repetition",
-"item.y",
-"pair",
-"lexicality.y", # Single-value column
-"handedness",
-"xrb",
-"one", # Single-value column
-"rb",
-"r", # Single-value column
-"corr", # Single-value column
-"corrn", # Single-value column
-"is_missing", # Single-value column
-"is_error", # Single-value column
-"is_bad_item",
-"is_lt_200", # Single-value column
-"is_gt_1999", # Single-value column
-"is_lt_lower", # Single-value column
-"is_gt_upper", # Single-value column
-"is_imputed", # Single-value column
)
data <- select(data, -"dim_type")
# Import the CSV with assigned diminutive values
dim_data <- read_csv("../corpus/dims_assigned.csv", show_col_types = FALSE)
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtC))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.66, is_error==0)
View(trialdata)
dim_data <- read_csv("../corpus/dims_assigned.csv", show_col_types = FALSE)
# Merge all datasets
dim_data <- inner_join(dim_data, data, by="spelling")
trialdata <- inner_join(dim_data, trials, by = "spelling")
# Clean up the trial dataset
trialdata <- distinct(trialdata)
# Make sure RT values are intact
trialdata <- filter(trialdata, complete.cases(trialdata$rtC))
# Remove all trials with low mean accuracy scores, exclude error responses too
trialdata <- filter(trialdata, acc.mean>=0.66, is_error==0)
# Filter out all single-value columns
trialdata <- rename(trialdata, "item"="item.x")
View(trialdata)
# Filter out all single-value and irrelevant columns
trialdata <- rename(trialdata, "item"="item.x")
trialdata <- select(trialdata,
-"lexicality.x", # Single-value column
-"Acc_dlp2", # Duplicated in column "acc.mean"
-"RT_dlp2", # Duplicated in column "rtC_mean"
-"PoS", # Single-value column
-"list", # Irrelevant for analysis
-"block", # Irrelevant for analysis
-"subblock", # Irrelevant for analysis
-"trial_in_block", # Irrelevant for analysis
-"trial_in_subblock", # Irrelevant for analysis
-"trial", # Irrelevant for analysis
-"observation", # Irrelevant for analysis
-"warmup", # Single-value column
-"repetition", # Irrelevant for analysis
-"item.y", # Duplicated in column "item"
-"pair", # Irrelevant for analysis
-"lexicality.y", # Single-value column
-"handedness", # Irrelevant for analysis
-"xrb", # Irrelevant for analysis
-"one", # Single-value column
-"rb",# Irrelevant for analysis
-"r", # Single-value column
-"corr", # Single-value column
-"corrn", # Single-value column
-"is_missing", # Single-value column
-"is_error", # Single-value column
-"is_bad_item", # Not sure what this one means
-"is_lt_200", # Single-value column
-"is_gt_1999", # Single-value column
-"is_lt_lower", # Single-value column
-"is_gt_upper", # Single-value column
-"is_imputed", # Single-value column
)
# Write the CSV as output for the analysis
write_csv(trialdata, file="../corpus/trialdata.csv")
knitr::opts_chunk$set(echo = TRUE)
# Get means for the diminutives
trialdata %>% group_by(dim_type) %>%
summarize(M = mean(rtC), SD = sd(rtC))
library(dplyr)
library(readr)
library(lme4)
library(car)
library(ggplot2)
options(scipen = 999)
trialdata <- read_csv("../corpus/trialdata.csv", show_col_types = FALSE)
# Move all relevant columns to the left for better readability
trialdata <- select(trialdata,
"spelling":"dec_criterion",
"rtC":"rateC",
"Length":"Colt_Nphon",
"item",
"participant",
"lower":"rateR",
"rtI":"zrateI",
"acc.mean":"zrateI.sd"
)
# Filter out the irrelevant columns based on theory-supported decisions
# NOTE: Done here so variables could be reintroduced at will if need be
trialdata <- select(trialdata,
# OLD20 chosen as the neighbourhood var: filter out the rest
-"Colt_N",
-"PLD30",
-"Colt_Nphon",
# RTs chosen as the dependent var; filter out the rest,
# do the centering and z-Transforming within the script;
# filter out the pre-existing variables
-"lower",
-"upper",
-"rtR",
-"rateR",
-"rtI",
-"rateI",
-"zrtC",
-"zrateC",
-"zrtI",
-"zrateI",
-"acc.mean",
-"acc.sd",
-"rtC.mean",
-"rtC.sd",
-"rateC.mean",
-"rateC.sd",
-"zrtC.mean",
-"zrtC.sd",
-"zrateC.mean",
-"zrateC.sd",
-"rtI.mean",
-"rtI.sd",
-"rateI.mean",
-"rateI.sd",
-"zrtI.mean",
-"zrtI.sd",
-"zrateI.mean",
-"zrateI.sd"
)
# Check for correlations using Pearson's R
summary(trialdata$SUBTLEX2)
# Motivate the log-transformation with reference to Winter 2020 and
# Smith and Levy 2013 therein
hist(trialdata$rtC)
trialdata$logRT <- log(trialdata$rtC)
hist(trialdata$logRT)
# Center and standardize vars like word length and freq
hist(trialdata$SUBTLEX2)
trialdata$logfreq <- log10(trialdata$SUBTLEX2 + 0.1)
hist(trialdata$logfreq)
trialdata <- mutate(trialdata,
logfreq_z = scale(logfreq),
len_z = scale(Length),
nsyl_z = scale(Nsyl),
old_z = scale(OLD20),
conc_z = scale(Concreteness),
aoa_z = scale(AoA),
wp_z = scale(Word_prevalence1))
# Get means for the diminutives
trialdata %>% group_by(dim_type) %>%
summarize(M = mean(rtC), SD = sd(rtC))
# Get means for the diminutives
trialdata %>% group_by(dim_type) %>%
summarize(M = mean(rtC), SD = sd(rtC))
# Run paired t-tests, see if the differences between those means are significant
df1 <- trialdata %>%
filter(dim_type == "both" | dim_type == "infl") %>%
select(dim_type, rtC)
df2 <- trialdata %>%
filter(dim_type == "infl" | dim_type == "deriv") %>%
select(dim_type, rtC)
df3 <- trialdata %>%
filter(dim_type == "deriv" | dim_type == "undecided") %>%
select(dim_type, rtC)
t.test(rtC ~ dim_type, data = df1)
t.test(rtC ~ dim_type, data = df2)
t.test(rtC ~ dim_type, data = df3)
trialdata %>% ggplot(aes(x = dim_type, y = logRT, fill = dim_type)) +
geom_boxplot() + theme_minimal() +
scale_fill_brewer(palette = "PuOr") %>%
ggsave("../figures/dim_box.png", width = 8, height = 6)
ggsave("../figures/dim_box.png", width = 8, height = 6)

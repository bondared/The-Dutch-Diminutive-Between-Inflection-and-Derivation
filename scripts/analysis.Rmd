---
title: "The Dutch Diminutive: Between Inflection and Derivation"
subtitle: "Analyis Script"
author: "Daniil Bondarenko"
date: '`r Sys.Date()`'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0. Important notice

This script is the only one you should need to run in order to replicate the results of the study. While "preprocessing.Rmd" relies on the externally-accessed DLP2 files in order to build the experimental dataset in the first place, here the dataset is already assembled and ready for final data transformations and subsequent analysis. If you're looking to get a full picture of the pipeline and account for every data-related step within this project, feel free to peek into the preprocessing script. Otherwise, you should be good to go!

## 1. Import the necessary R packages
```{r preamble, echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr) # For data cleanup and transformations
library(readr) # For more straightforward ways to import/export data
library(lme4) # For mixed-effects linear regression modelling
library(car) # For alternative options when it comes to plots and regressions
library(ggplot2) # For a more comprehensive way of plotting data
library(ggpubr) # For including statistical values in plots
library(effsize) # For Cohen's d, etc.
library(afex) # For p-values in lmer summaries
library(MuMIn) # For extracting R-squared values from lmers
options(scipen = 999) # For easier interpretability of the slopes
```

## 2. Import the experimental dataset, perform some final cleanup
```{r data_import}
trialdata <- read_csv("../corpus/trialdata.csv", show_col_types = FALSE)
# Move all relevant columns to the left for better readability
trialdata <- select(trialdata,
                    "spelling":"dec_criterion",
                    "rtC":"rateC",
                    "Length":"Colt_Nphon",
                    "item",
                    "participant",
                    "lower":"rateR",
                    "rtI":"zrateI",
                    "acc.mean":"zrateI.sd"
)
# Filter out the irrelevant columns based on theory-supported decisions
# NOTE: Done here so variables could be reintroduced at will if need be
trialdata <- select(trialdata,
                    -"N_phonemes",
                    # OLD20 chosen as the neighbourhood var: filter out the rest
                    -"Colt_N",
                    -"PLD30",
                    -"Colt_Nphon",
                    # RTs chosen as the dependent var; filter out the rest,
                    # do the centering and z-Transforming within the script;
                    # filter out the pre-existing variables
                    -"lower",
                    -"upper",
                    -"rtR",
                    -"rateR",
                    -"rtI",
                    -"rateI",
                    -"zrtC",
                    -"zrateC",
                    -"zrtI",
                    -"zrateI",
                    -"rtC.mean",
                    -"rtC.sd",
                    -"rateC.mean",
                    -"rateC.sd",
                    -"zrtC.mean",
                    -"zrtC.sd",
                    -"zrateC.mean",
                    -"zrateC.sd",
                    -"rtI.mean",
                    -"rtI.sd",
                    -"rateI.mean",
                    -"rateI.sd",
                    -"zrtI.mean",
                    -"zrtI.sd",
                    -"zrateI.mean",
                    -"zrateI.sd"
)
```

## 3. Run sanity checks
```{r sanity}
# Make sure the response variable looks fine
summary(trialdata$rtC) # Seems some responses are unreasonably long
densityPlot(trialdata$rtC) # Few past 1000, even fewer past 1500
cat(
  "Only", NROW(filter(trialdata, rtC > 1500)), "observations past 1500 \n",
  "Only", NROW(filter(trialdata, rtC > 1250)), "observations past 1250 \n",
  "Only", NROW(filter(trialdata, rtC > 1000)), "observations past 1000 \n"
)

# Need to subset by some number; 1250 as the sweet spot.
# NOTE: not subsetting the data here leads to an pretty awful skew in model
# residuals; seems not even log-transforming the rt value is enough to
# eliminate the effect of these more extreme values.
trialdata <- filter(trialdata, rtC < 1250)

# Compare number of rows per diminutive condition
trialdata <- mutate(trialdata, dim_type=factor(dim_type))
summary(trialdata$dim_type)

# Check distributions of all relevant predictors
trialdata %>% select("SUBTLEX2",
                     "Length",
                     "Nsyl",
                     "nmorph",
                     "OLD20",
                     "Concreteness",
                     "AoA",
                     "Word_prevalence1") %>% summary()

# Check for correlations using Pearson's R
cat(
  "SUBTLEX2~Length =", cor(trialdata$SUBTLEX2, trialdata$Length), "\n",
  "Length~Nsyl =", cor(trialdata$Length, trialdata$Nsyl), "\n",
  "Length~nmorph =", cor(trialdata$Length, trialdata$nmorph), "\n",
  "Nsyl~nmorph =", cor(trialdata$Nsyl, trialdata$nmorph), "\n",
  "Length~OLD20 =", cor(trialdata$Length, trialdata$OLD20), "\n",
  "nmorph~OLD20 =", cor(trialdata$nmorph, trialdata$OLD20)
)

# Both length and morpheme count pretty highly correlated with syllable count;
# Keeping Nsyl has much less of a theoretical reason and might impact the
# effects of the other two predictors; exclude it from the analysis.
trialdata <- select(trialdata, -"Nsyl")

# There's only two items past the 11000 mark
par(mfrow = c(1, 2))
with(trialdata, plot(SUBTLEX2, rtC)) 
with(trialdata, plot(SUBTLEX2, acc.mean))
# Find out what they are
trialdata %>% 
  select("spelling", "SUBTLEX2") %>%
  distinct() %>% 
  arrange(desc(SUBTLEX2)) %>%
  head()
# "beetje" and "meisje" both have egregiously extreme freq values;
# all the more reason to use Zipf-vals (See SUBTLEX-UK by Van Heuven et al., 2014)
```

## 4. Finalise fine preprocessing
```{r final_preprocessing}
# Optional step: exclude the non-core diminutive items first, 
# i.e. the ones with multiple ways to parse.
# NOTE: make sure to change contrasts below!
trialdata <- filter(trialdata, dim_type !="both")

# Log-transform reaction times using the base logarithm (see Winter 2019)
trialdata$logRT <- log(trialdata$rtC)
par(mfrow = c(1, 2))
hist(trialdata$rtC)
hist(trialdata$logRT)

# Zipf-values for frequency (see Van Heuven et al., 2014)
trialdata$freq_zipf <- log10(trialdata$SUBTLEX2+0.01)+3
par(mfrow = c(1, 2))
hist(trialdata$SUBTLEX2)
hist(trialdata$freq_zipf)

# Standardise all the relevant predictors for an easier comparison of effect size
trialdata <- mutate(trialdata,
                    zipf_z = scale(freq_zipf),
                    len_z = scale(Length),
                    nmorph_z = scale(nmorph),
                    old_z = scale(OLD20),
                    conc_z = scale(Concreteness),
                    aoa_z = scale(AoA),
                    # Word prevalence already standardised, just center
                    wp_z = scale(Word_prevalence1, scale = FALSE))

```

## 5. Descriptive Statistics
```{r boxplot_stats_setup, include=FALSE}
get_box_stats <- function(y, upper_limit = max(trialdata$logRT) * 1.1) {
  return(data.frame(
    y = 0.95 * upper_limit,
    label = paste(
      "Count =", length(y), "\n",
      "Mean =", round(mean(y), 2), "\n",
      "Median =", round(median(y), 2), "\n"
    )
  ))
}
```


```{r desc_stats}
# Get means for the diminutives
trialdata %>% group_by(dim_type) %>% 
  summarize(M = mean(rtC), SD = sd(rtC))

# Make a plot with all the relevant statistics, throw in a t-test as well
trialdata %>% ggplot(aes(x = dim_type, y = logRT, fill = dim_type)) +
  stat_boxplot(geom ='errorbar', linewidth=1, width=.5) + 
  geom_boxplot(lwd=1, width=.7, show.legend = FALSE) + theme_minimal() +
  labs(
    x = "Diminutive Type",
    y = "Reaction Times",
  ) +
  scale_x_discrete(labels=c('Derivational', 'Inflectional')) + 
  stat_summary(fun.data = get_box_stats, geom = "text", hjust = 0.5, vjust = 0.9) +
  scale_fill_brewer(palette = "Paired") +
  stat_compare_means(method="t.test", label.y = 6.0, label.x = 1.35)
# Save the plot for later
ggsave("../figures/dim_box.png", width = 8, height = 6)
```

## 6. Inferential Statistics

Here, we will finally handle some tests that will let us draw conclusions from the sample about the population at large. We start with assigning contrasts, then run a simple t-test and then move on to modelling.

```{r contrasts_prep, include=FALSE}
# Prepare the diminutive variable: check contrasts
trialdata <- mutate(trialdata, dim_type=factor(dim_type))
```

### 6.1. Contrasts and t-tests
The next two code chunks handle the contrast coding; they are mutually exclusive depending on the decision to include observations with "both" as a value for dim_type. In order to switch between them, go to the chunk options and specify *eval=FALSE* to stop the script from running the code and *include=FALSE* to prevent the code from being included in the final knitted document.

The motivation for sum-coding between "deriv" and "infl" is taken from Winter 2020, where it is argued that sum-coding is better suited for mixed-effects models with interactions and random effects; additionally, sum-coding is argued to make the coefficients easier to interpret.

```{r contrasts_sum}
# Sum-coding for a purely deriv/infl dataset (see above)
contrasts(trialdata$dim_type) <- contr.sum(2)
contrasts(trialdata$dim_type)
t.test(rtC ~ dim_type, data = trialdata)
t.test(logRT ~ dim_type, data = trialdata)
cohen.d(rtC ~ dim_type, data = trialdata)
cohen.d(logRT ~ dim_type, data = trialdata)
```

The motivation for Helmert-coding between "deriv", "infl", and "both" is simple: for wordforms with either "deriv" or "infl", a single decomposition pipeline is proposed. Assuming structural differences, recognizing either is the same type of operation being performed in a different location in the structure. Compare with "both", where the decomposition apparatus presumably pursues both leads at once; therefore, this should be reflected in the coding as such:

  - First, compare the differences between deriv and infl (either x or y)
  - Then, compare their average RTs to both (x and y at the same time)
  
```{r contrasts_helmert, eval=FALSE, include=FALSE}
# Helmert coding for deriv/infl/both dataset:
# Compare the means of deriv and infl, then compare their average to both
ctrMatrix <- cbind(c(0, -1, 1), c(-2, 1, 1))
contrasts(trialdata$dim_type) <- ctrMatrix
contrasts(trialdata$dim_type)
# Run paired t-tests, see if the differences between those means are significant
df1 <- trialdata %>%
    filter(dim_type == "deriv" | dim_type == "infl") %>%
    select(dim_type, rtC)
df2 <- trialdata %>%
    filter(dim_type == "infl" | dim_type == "both") %>%
    select(dim_type, rtC)
df3 <- trialdata %>%
    filter(dim_type == "both" | dim_type == "deriv") %>%
    select(dim_type, rtC)
t.test(rtC ~ dim_type, data = df1)
t.test(rtC ~ dim_type, data = df2)
t.test(rtC ~ dim_type, data = df3)
```

### 6.2. Modelling

The formula for the experimental model closely follows the formula reported in the DLP2 paper, with the addition of two predictors:

  a. dim_type, a factor with values "deriv" and "infl" (possibly "both" for the expanded dataset)
  b. nmorph, a numeric with values reflecting the (observable and theoretically motivated) morpheme count in the structure of each wordform: assuming full decomposition, every word is broken down to the most primitive units (= morphemes), so it logically follows that the more morphemes a wordform consists of, the more there is to break down and recompose, and the more time it should take to recognize a word.
  
Note the absence of two predictors reported for the DLP2 model, namely Nsyl and Length. The justification for both is the high degree of correlation between Length, Nsyl, nmoprh and OLD20 as explanatory variables that all in some ways have to deal with length. Nsyl, the number of syllables, was excluded first in favour of the more theoretically relevant nmoprh. Dropping length was a tough decision that was ultimately made after some stepwise modelling to establish which of the two factors, length or OLD20, would contribute more to explaining the variance in the dataset.
  
The final formula of the model is therefore this (see "mod_full" below):

***RT ~ Diminutive Type*Frequency + Morpheme count + OLD20 ratings + Concreteness + Age of acquisition + Word prevalence + Varying intercepts by participant and by item***

```{r base_model}
# Run the base model with only frequency and random intercepts
# Mention including the participant slopes and item intercepts as the 
# motivation to satisfy the independence assumption (Winter 2020, Ch.14)
mod_base <- lmer(logRT ~ zipf_z + 
                   (1|participant) + 
                   (1|item), data = trialdata, REML = TRUE)
summary(mod_base) # Make sure the frequency findings aren't wildly off
r.squaredGLMM(mod_base)

hist(residuals(mod_base), col = 'skyblue2') # Plot 1, histogram
qqPlot(residuals(mod_base)) # Plot 2, Q-Q plot
plot(fitted(mod_base), residuals(mod_base)) # Plot 3, residual plot
```


```{r stepwise_bollocks, eval=FALSE, include=FALSE}
# A purely exploratory chunk where all the predictors are added one-by-one
# to assess relative model performance (just crossing the "t"s and dotting the "i"s)

mod.null <- lmer(logRT ~ 1 + (1|participant), data = trialdata)
mod.null.item <- lmer(logRT ~ 1 + (1|participant) + (1|item), data = trialdata)
anova(mod.null, mod.null.item) # Better

mod.base <- lmer(logRT ~ zipf_z + (1|participant) + (1|item), data = trialdata)
anova(mod.null.item, mod.base) # Better
r.squaredGLMM(mod.base) # Fixed effects: 4.3%; Fixed+Random: 42.6%

mod.len <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.base, mod.len) # Better
summary(mod.len) # Length statistically significant
# Length barely contributes to explaining the variance
r.squaredGLMM(mod.len) # Fixed effects: 4.7%; Fixed+Random: 42.6%
vif(mod.len) # Variance Inflation Factors OK

mod.flm <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   nmorph_z +
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.len, mod.flm) # Not better
# Length still statistically significant, but p is lower
# Nmorph is not significant at all
summary(mod.flm) 
# Barely any contribution to explaining the variance
r.squaredGLMM(mod.flm) # Fixed effects: 4.7%; Fixed+Random: 42.6%
vif(mod.flm) # Variance Inflation Factors higher for Length and Nmorph, but still OK

mod.flmo <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   nmorph_z +
                   old_z +
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flm, mod.flmo) # Better
# OLD20 significant, Length AND Nmorph not significant at all
summary(mod.flmo) 
# Small contribution to explaining the variance
r.squaredGLMM(mod.flmo) # Fixed effects: 4.8%; Fixed+Random: 42.7%
vif(mod.flmo) # VIFs for Length and OLD20 skyrocketing

mod.flmoc <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flmo, mod.flmoc) # Better
# Concreteness significant, OLD20 too, Length AND Nmorph not
summary(mod.flmoc) 
# Small contribution to explaining the variance
r.squaredGLMM(mod.flmoc) # Fixed effects: 5%; Fixed+Random: 42.7%
vif(mod.flmoc) # VIFs for Length and OLD20 high, but stable

mod.flmoca <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flmoc, mod.flmoca) # Better
# Concreteness not significant anymore, AoA highly significant, others stable
summary(mod.flmoca) 
# Small contribution to explaining the variance
r.squaredGLMM(mod.flmoca) # Fixed effects: 5.6%; Fixed+Random: 42.6%
vif(mod.flmoca) # VIFs for Length and OLD20 high, but stable

mod.flmocaw <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flmoca, mod.flmocaw) # Better
# WP highly significant, others stable
summary(mod.flmocaw) 
# Small contribution to explaining the variance
r.squaredGLMM(mod.flmocaw) # Fixed effects: 6%; Fixed+Random: 42.6%
vif(mod.flmocaw) # VIFs for Length and OLD20 high, but stable

# OLD20 significant, but inflates variance together with Length;
# Length correlated with nmorph; keep one or the other

mod.fmocaw <- lmer(logRT ~ 
                   zipf_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flmocaw, mod.fmocaw) # Not better than having both
# No change in most, but OLD20 is now more significant
summary(mod.fmocaw) 
# No change in explaining the variance
r.squaredGLMM(mod.fmocaw) # Fixed effects: 6%; Fixed+Random: 42.6%
vif(mod.fmocaw) # VIF for OLD20 below threshold now

mod.flocaw <- lmer(logRT ~ 
                   zipf_z + 
                   len_z + 
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.flmocaw, mod.flocaw) # Not better than having both
# No change in most, but OLD20 is now more significant
summary(mod.flocaw) 
# No change in explaining the variance
r.squaredGLMM(mod.flocaw) # Fixed effects: 6%; Fixed+Random: 42.6%
vif(mod.flocaw) # VIFs for Length and OLD20 still very high

# Keep nmorph, proceed to the full model
mod.full.noslope <- lmer(logRT ~ 
                   dim_type + 
                   zipf_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.fmocaw, mod.full.noslope) # Not better
# No change in most, but OLD20 is now more significant
summary(mod.full.noslope) 
# Slight change in explaining the variance
r.squaredGLMM(mod.full.noslope) # Fixed effects: 6.1%; Fixed+Random: 42.6%
vif(mod.full.noslope) # VIF for OLD20 below threshold now, others fine

mod.full.withslope <- lmer(logRT ~ 
                   dim_type + 
                   zipf_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (dim_type|participant) + 
                   (1|item), data = trialdata) # Singular fit for slope
anova(mod.full.noslope, mod.full.withslope) # Not better
# No change in most, but OLD20 is now more significant
summary(mod.full.withslope) 
# Little change in explaining the variance
r.squaredGLMM(mod.full.withslope) # Fixed effects: 6.1%; Fixed+Random: 42.6%
vif(mod.full.withslope) # VIF for OLD20 below threshold now, others fine

# Interactions? 
mod.int.noslope <- lmer(logRT ~ 
                   dim_type*zipf_z + 
                   nmorph_z +
                   old_z +
                   conc_z +
                   aoa_z + 
                   wp_z + 
                   (1|participant) + 
                   (1|item), data = trialdata)
anova(mod.full.noslope, mod.int.noslope) # Slightly better
# No change in most, but OLD20 is now more significant
summary(mod.int.noslope) 
# Little change in explaining the variance
r.squaredGLMM(mod.int.noslope) # Fixed effects: 6.1%; Fixed+Random: 42.6%
vif(mod.int.noslope) # VIF for OLD20 below threshold now, others fine
```

```{r full_model}
# Run the full model
mod_full <- lmer(logRT ~ 
                dim_type*zipf_z +
                nmorph_z +
                old_z +
                conc_z +
                aoa_z +
                wp_z + 
                (1|participant) +
                (1|item), data = trialdata)
summary(mod_full)
Anova(mod_full)
r.squaredGLMM(mod_full) # Fixed effects: 6.1%; Fixed+Random: 44%
vif(mod_full) # Get variance inflation factors to check for collinearity
hist(residuals(mod_full), col = 'skyblue2') # Plot 1, histogram
qqPlot(residuals(mod_full)) # Plot 2, Q-Q plot
plot(fitted(mod_full), residuals(mod_full)) # Plot 3, residual plot
fixef(mod_full)
model_table <- as.data.frame(round(summary(mod_full)$coefficients, 4))
print(model_table)
```
\chapter{The Functional Split Proposal}\label{chp:proposal}
The previous chapter examined the Dutch diminutive suffix \textit{-tje} along the formal and semantic criteria typical for the process of diminutive formation and discussed the problematic of its alignment along the inflection/derivation distinction. While an in-depth analysis confirmed \textit{-tje} to be the prototypical diminutive morpheme, various theoretical claims regarding its morphological status have proved inconclusive. This chapter adopts an additional structural analysis of the diminutive suffix within the theoretical framework of Diminutive Morphology (\citeauthor{Halle+Marantz+1993} \citeyear{Halle+Marantz+1993}, \citeyear{Halle+Marantz+1994}) and operationalises its predictions for empirical testing in a visual word processing experiment. 

The chapter assumes the following structure: Section~\ref{sec:3-dm} outlines the key assumptions of Distributed Morphology and its relation with the theoretical frameworks behind the discussion in Chapter~\ref{chp:background}. Section~\ref{sec:3-split-dim} then presents the arguments for the analysis of the Dutch diminutive presented in \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}): the idea of a functional split is proposed, with diminutive forms showed to vary in terms of structural complexity depending on the function that \textit{-tje} plays in their structure. Section~\ref{sec:3-preds} then converts this observation into testable predictions for a visual word processing experiment with reference to the \textit{Obligatory Decomposition Model} (\citeauthor{Taft+1979} \citeyear{Taft+1979}).

\section{Distributed Morphology}
\label{sec:3-dm}
The theoretical discussion in Chapter~\ref{chp:background} has largely referenced approaches rooted in the Lexicalist Theory, a generative approach to morphology that relegates the process of word formation to the module of the lexicon (\cite{Schneider+2003}). Offshoots of the Lexicalist Theory all assume that the lexicon is both a storage facility of sorts for the most basic elements of language, i.e. morphemes, as well as a system of rules that generates words by combining these morphemes into more complex objects, possibly storing some complex forms as well if their patterns of meaning or behaviour are not predictable based on those of their constituent parts (\cite{Embick+2015}). The output of the lexicon is thus a word that is then fed into the pipeline responsible for creating syntactic objects, indicating a clear split between syntax as the module responsible for forming multi-word structures and morphology as the module associated with rules and patterns of word formation. Lexicalist theories additionally differ in terms of how strong they assume this split to be: the Strong Lexicalist Hypothesis as adopted in \citeauthor{Scalise+1986} assumes that both derivation and inflection are morphological processes confined within the lexicon, while the Weak Lexicalist Hypothesis assumes that only derivation is pre-syntactic, defining inflection as a syntactic process instead (\cite{Booij+2000}).

The work of \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) instead adopts Distributed Morphology (DM; \citeauthor{Halle+Marantz+1993} \citeyear{Halle+Marantz+1993}, \citeyear{Halle+Marantz+1994}) as its theoretical framework. What sets DM apart from the theories outlined above is the rejection of the syntax-lexicon split in favour of the assumption that every single linguistic structure is the work of one module, namely syntax. In other words, syntax is responsible for building not just sentences, but words as well, as the structures of both are assumed to share the same underlying mechanism. What follows from this analysis is the notion of \textit{full decomposition} (\cite{Embick+2015}): all complex (i.e. multimorphemic) structures are constructed from the ground up every time, and no complex forms are optionally stored in the lexicon. Both inflection and derivation are seen as syntactic processes that operate on different levels in the structure, while the lexicon is interpreted as a system of interconnected lists distributed between these levels as well.

The first list exists on the syntactic level and is comprised of primitives or \textit{Syntactic Terminals} (\cite{Embick+2015}). These terminals come in two flavours, depending on whether they code any grammatical information or not. The first type of terminal is the functional morpheme, an abstract bundle of grammatical information like [definite] and [determiner] assumed to be devoid of phonological form in its representation. The second type is the root, a terminal that codes no grammatical information and is usually assumed to have an underlying phonological form. Examples of roots are such morphemes as $\surd$\textsc{cat}, $\surd$\textsc{yellow}, and $\surd$\textsc{sleep}.

The terminals form the building blocks of the syntactic structure, with each terminal assigned to a syntactic node. 
Once the process of structure-building is finished, these terminals are realised, or spelled out, using the entries from a different list, called the \textit{Vocabulary}. The vocabulary tries to match the overt form that best fits the requirements of the specific syntactic node. For example, in the case of German, the syntactic node responsible for assigning a determiner would first be filled by a terminal with the relevant information, e.g. [definite] and [neuter]. The vocabulary then works its way through the list of items that best satisfy these conditions: it selects an overt determiner form marked for [definite], narrowing the choice down to \textit{der}, \textit{die}, or \textit{das}, and then selects the only one that best matches the requirements, taking \textit{das} as the form marked for [neuter]. The node is then spelled out as \textit{das} and forms a part of the larger structure, with every other node undergoing the same process. The final list called the \textit{Encyclopedia} stores special semantic information and aspects of world knowledge used in meaning interpretation (\cite{Embick+2015}). 

On the syntactic level, the lowest node in every substructure is the root node. Root nodes are assumed to lack information such as word class, with special nodes called \textit{category heads} specifying their word category farther up in the syntactic structure (\cite{Embick+2015}). Thus, a root like $\surd$\textsc{sleep} can have its category be determined by the category of the head node, resulting in the noun \textit{sleep} or the verb \textit{sleep}. Since nouns and verbs have vastly different inflectional patterns, it follows that inflectional processes take place in the structure above the category head. On the other hand, categorical heads themselves are assumed to be realised by derivational affixes, the most basic of which is the purely functional $\varnothing$, or zero-morpheme (\cite{Embick+2015}). 

The mechanisms of inflection and derivation therefore apply on the opposite sides of the divide marked by the category head node. In fact, DM also assumes that syntactic structures are formed and spelled out in cycles, with certain nodes such as the category head triggering spell-out before the resulting structure can be incorporated into a larger whole. As such, the derivation-inflection split is defined by inflectional processes applying only after the product of derivational processes has been fully spelled out, reflecting the previously addressed observation that inflection is more peripheral than derivation. This structural distinction between inflection and derivation forms the core the argument in \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}), presented below.

\section{The Dutch Diminutive and the Functional Split}
\label{sec:3-split-dim}
\citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) propose that there are two types of diminutives and take the difference in compositionality of meaning as the determining one. Thus, semantically transparent diminutives like \textit{appetlje} are taken to belong to a different type than the opaque ones like \textit{groentje}. The argument for this comes from the Italian suffix \textit{-ino}: while it does produce transparent forms like \textit{gattino} "cat+DIM", it is also responsible for semi- and fully opaque words like \textit{panino} "sandwich" and \textit{casino} "brothel". \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) reason that the two groups behave differently in terms of semantics: while the words in the transparent group receive a meaning augmentation Ã  la "small X", the opaque ones do not; hence, the opaque words should be able to combine with other suffixes pertaining to size, such as the augmentative \textit{-one}. This prediction holds true: *\textit{gatt-in-one} "big cat+DIM" is unlicensed, while \textit{pan-in-one} "big sandwich" and \textit{cas-in-one} "big brothel" are completely well-formed. The authors then propose that the differences between the two groups can be explained in terms of their different syntactic structures, with one group attaching above the category head node and the other below it. In other words, the compositionality of meaning varies depending on whether a suffix is inflectional or derivational in nature.

The proposed split structure of diminutive nouns is presented in (\ref{ex:debeldersprelim}). nP, the categorical head phrase, neatly separates the two halves, assigning the category of noun to the preceding structure and demarcating the boundary between inflection above it and derivation below it. What \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) propose is that the inflectional diminutive occupies the functional head Size\textsuperscript{0}, while the derivational one occupies the position in Lex\textsuperscript{0} and modifies the root $\surd$ by directly attaching to it before the category head. The motivations for this particular structure are outlined below. 

Recall the observations on the quantificational capabilities of diminutives in Dutch in (\ref{ex:dutchquants}), taken from \citeauthor{DeBelder+2008} (\citeyear{DeBelder+2008}). In structural terms, she argues that the mass-to-item meaning shift in Dutch comes from an interplay of the two functional heads attaching above the category head. Div\textsuperscript{0}, adopted from \citeauthor{Borer+2005} (\citeyear{Borer+2005}), is taken to quantify the noun: its presence in the structure switches a mass reading to a kind reading in Dutch. However, the presence of Div\textsuperscript{0} alone is not enough to produce an item reading.

\begin{exe}
\ex \label{ex:debeldersprelim}
\Tree [.DivP [ ] [.Div\1 [.Div\0 ] [.SizeP [ ] [.Size\1 [.Size\0 ] [.nP [ ] [.n\1 [.n\0 ] [.LexP [ ] [.Lex\1 [.Lex\0 ] [.$\surd$ !\qsetw{1cm} ] ] ] ] ] ] ] ] ]
\end{exe}

 Based on this observation, \citeauthor{DeBelder+2008} (\citeyear{DeBelder+2008}) proposes an additional functional head Size\textsuperscript{0}, which introduces a scalar component by making the noun measurable. The diminutive suffix, at least in the semantically transparent nouns, has been established as introducing scalarity, and its presence is obligatory to force an item reading in Dutch. By attaching to a noun, the suffix makes it measurable and inherently quantifies it, always triggering an individual reading. It stands to reason, then, to assume that Size\textsuperscript{0} is the functional head occupied by the diminutive suffix.

While the motivation for assuming Size\textsuperscript{0} as the locus of attachment for the inflectional suffix is clear, why is it necessary to assume Lex\textsuperscript{0} as the locus for the derivational one, especially since DM assumes category heads to be realised by derivational morphemes as well? The argument for this additional head comes from \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014})'s observations in Modern Hebrew and Italian, with the examples using the Italian diminutive suffix \textit{-ett-} presented in (\ref{ex:fischiett}). 

\begin{exe}
\ex \label{ex:fischiett}
\textit{fischi-ett-o} vs. \textit{fischi-ett-are} (\cite{DeBelder+etal+2014}:10)
\begin{multicols}{2}
\begin{xlist}
\ex \label{ex:fischiett-o}
\textit{fischi-ett-o} "whistle (object)" \par \medskip
\Tree [.n [.n ] [.LexP [.\textit{ett} ] [.$\surd$\textsc{fischi} ] ] ]
\columnbreak
\ex \label{ex:fischiett-are}
\textit{fischi-ett-are} "whistle (pluract.)" \par \medskip
\Tree [.v [.v ] [.LexP [.\textit{ett} ] [.$\surd$\textsc{fischi} ] ] ]
\end{xlist}
\end{multicols}
\end{exe}

The argument goes as follows: both the noun \textit{fischi-o} "whistle (action)" and the verb \textit{fischi-are} "to whistle" are known to exist. They take the same root $\surd$\textsc{fisci} as their base, with the category head determining the word class of the output, which is subsequently coded for the inflectional features of that word class farther up in the structure. However, both a noun and a verb exist that seem to be formed from the combination of the root and the suffix \textit{-ett-}. Since the suffix is not category-determining, it cannot function as the category head; conversely, it is clearly derivational and must therefore stay within the domain of derivation as demarcated by that same category head. The only possible conclusion is that the suffix occupies an additional category-less lexical head, e.g. Lex\textsuperscript{0}.

This proposal comes with a few corollaries that the authors examine in order to see if those hold true. The first corollary of this proposal is the possibility of the two diminutive functions being realised by different morphemes. This is precisely what \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) find to be the case in Modern Hebrew, where the fully productive inflectional suffix \textit{-on} can freely attach to nouns like \textit{bacal} "onion" and \textit{xamor} "donkey", with the resulting forms \textit{bacal-on} and \textit{xamor-on} showing full transparency of meaning and fitting the semantic mold of "small X". Conversely, the formation pattern involving reduplication, e.g. \textit{bacal} --- \textit{bcalcal}, is taken to be derivational: it is neither semantically transparent (\textit{bcalcal} means "shallot" and not "small onion") nor fully productive, as *\textit{xamarmor} is not licensed. Compared and contrasted with both the Italian \textit{-ino} and the Dutch \textit{-tje}, the authors assume that both languages use the same morpheme in both positions.

But if there are essentially two diminutive structures, should they not combine in certain cases? This is the second corollary of \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014})'s analyis. As the authors attest, Modern Hebrew \textit{xazarzir-on} "small piglet" (< \textit{xazarzir} "piglet"  < \textit{xazir} "pig") provides an example where both of them apply in the same wordform. They assume the same structure for the Italian forms like \textit{pan-in-etto} "sandwich+DIM" and Polish \textit{stÃ³Å} "table" > \textit{stoÅ-ek} table-DIM, "chair" > \textit{stÃ³Å-ecz-ek} table-DIM-DIM, "chair+DIM". In languages where the same morpheme is used in both structures, then, what seems like recursive application is a very distinct possibility. This analysis therefore explains the observations for evaluative suffixes in \citeauthor{Scalise+1986} (\citeyear{Scalise+1986}), particularly (b) and (d) from (\ref{ex:scaliseevals}), in different structural terms. However, it seems that additional factors can play a role in whether a diminutive suffix can attach recursively: a string like \textit{-tje-je} in *\textit{groen-tje-je} is unlicensed. In a footnote, \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) suggest that this restriction might be due to Dutch dispreferring two unstressed syllables in a row, an observation supported by data in \citeauthor{Booij+1998} (\citeyear{Booij+1998}) (however, see the discussion in \cite{taalportaal} for potential problems of this explanation).

Another corollary is that each of the diminutive suffix types should be able to occur independently. Echoing back to the observation in \citeauthor{Schneider+2003} (\citeyear{Schneider+2003}), there should be languages in the world with only the derivational diminutive type, just as there should be languages with only inflectional diminutives. \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) take examples from English, French, and Egyptian Arabic, to show that diminutive structures are available in the languages they take to be restricted to the derivational diminutive type, e.g. the English \textit{pumpkin} and \textit{napkin}, or French \textit{fill-ette} girl-DIM, "young girl". As for the exclusively inflectional type, they argue that it would be an empirical challenge to find a language without a single semantically opaque formal diminutive, i.e. one with purely compositional diminutive meaning. Nevertheless, the assumption of the two structures being independent is satisfied as far as the authors are concerned.

The analysis in \citeauthor{DeBelder+etal+2014} (\citeyear{DeBelder+etal+2014}) is empirically motivated and theoretically sound, building up on decades of previous research and providing convincing explanations for the problematic morphological nature of the Dutch diminutive. The paradigm of \textit{-tje} is thus effectively split between inflection and derivation, with the suffix attaching in different locations in the structure depending on whether it realises a functional head or is instrumental in derivational processes instead. 

The trees in (\ref{ex:dims-infl-deriv}) summarize the structural differences between an inflectional diminutive such as \textit{bier-tje} "a serving of beer" and a derivational one like \textit{groen-tje} "novice": \textit{biertje} is an instance of a mass-to-item reading shift and does not feature the optional derivational projection LexP, with the noun category assigned by the head n\textsuperscript{0}, while \textit{groentje} is a semantically opaque formally diminutive noun necessitating an additional derivational step in LexP before category assignment through n\textsuperscript{0}. Since one refers to a single serving of beer and the other to an individual, both require the heads Div\textsuperscript{0} and Size\textsuperscript{0}, as argued in \citeauthor{DeBelder+2008} (\citeyear{DeBelder+2008}).

\begin{exe}
\ex \label{ex:dims-infl-deriv}
The functional split of the Dutch diminutive suffix
\begin{multicols}{2}
\begin{xlist}
\ex \label{ex:dims-infl}
Inflectional diminutive \par \medskip
\Tree [.DivP [ ] [.Div\1 [.Div\0 ] [.SizeP [ ] [.Size\1 [.Size\0 \textit{-tje} ] [.nP [ ] [.n\1 [.n\0 ] [.$\surd$\textsc{bier} ] ] ] ] ] ] ] 
\par ~~
\par ~~
\par ~~
\par ~~
\par ~~
\par ~~
\columnbreak
\ex \label{ex:dims-deriv}
Derivational diminutive \par \medskip
\Tree [.DivP [ ] [.Div\1 [.Div\0 ] [.SizeP [ ] [.Size\1 [.Size\0 ] [.nP [ ] [.n\1 [.n\0 ] [.LexP [ ] [.Lex\1 [.Lex\0 \textit{-tje} ] [.$\surd$\textsc{groen} ] ] ] ] ] ] ] ] ]
\end{xlist}
\end{multicols}
\end{exe}

All other things being equal, the difference in patterns of meaning compositionality within words formed with the Dutch diminutive suffix \textit{-tje} reflects its role in the underlying syntactic structure, which in turn depends on whether the suffix is used in its inflectional or derivational capacity. Assuming that all differences between the two structures have been accounted for in the trees in (\ref{ex:dims-infl-deriv}), a clear imbalance can be observed in terms of structural complexity, with derived diminutive words requiring an additional projection before merging with the category-assigning head. This observation carries important implications for the domain of lexical processing and offers a distinct possibility for empirical corroboration through a lexical decision experiment, discussed in the following section.

\section{Predictions for Lexical Processing}
\label{sec:3-preds}
Now that the distinction between the inflectional and the derivational diminutive suffix has been worded in terms of differences in structural complexity, it is time to turn to ways of testing the effect of those differences in practical terms, and the field of psycholinguistics is the perfect place to start. The core of psycholinguistic research is made up of connecting quantifiable patterns of behaviour with underlying linguistic processes. For example, eye tracking experiments try to make inferences about the way humans extract lexical and grammatical meaning from linguistic stimuli based purely on observed patterns of eye movement. By changing variables like the length or modality of the stimulus, or using whole clauses as stimuli instead of words, and manipulating the lexical or grammatical properties of the stimulus, researchers in eye-tracking have been able to examine a wide variety of linguistic phenomena.

Lexical decision experiments share the same concept at their core: they present participants with a stimulus, usually a string of characters on a screen in the case of visual word processing experiments, and ask them whether the string they see constitutes a real word or not. Depending on the predetermined features of the input and the participant response, logical inferences can be made about the structures in which human beings process and store lexical units. The variables most frequently used to quantify participant responses are reaction times, measured in milliseconds, and accuracy ratings calculated based on how well the participants have performed in correctly identifying words and rejecting nonwords. The variables that are adjusted in order to elicit particular responses and test predictions are largely theory-dependent and tend to vary. 

Structural complexity is one such theory-dependent variable and comes with an established history of use within visual word processing experiments (\citeauthor{Taft+1979} \citeyear{Taft+1979}, \citeyear{Taft+2004}; \citeauthor{Rastle+etal+2004} \citeyear{Rastle+etal+2004}; \citeauthor{Stockall+Marantz2006} \citeyear{Stockall+Marantz2006}, among others). In fact, \citeauthor{Rastle+etal+2004} (\citeyear{Rastle+etal+2004}) use evidence from masked priming experiments to argue that morphological information takes precedence in the lexical decision of structurally complex words, and that its effects cannot be explained through a simple interplay of orthographic and semantic information. However, the precise predictions concerning the effects of morphological complexity depend on the working theory, and in this case they are subject to the assumptions advanced within Distributed Morphology. 

The central and most important assumption is that of \textit{full decomposition} (\cite{Embick+2015}): every structure, even a single word, is internally complex as long as it consists of multiple morphemes. As has been observed above, within DM this would make every single well-formed noun, verb, or member of any other word class a complex word, since the most basic process of word-building employs a root and some sort of derivational suffix acting as a category-assigning head (\cite{Embick+2015}). Every word is thus constructed on-line in the cyclic process of syntactic structure construction and vocabulary insertion; no words are considered to be stored in any of the lexical lists outlined in Section~\ref{sec:3-dm}: there are only roots and functional morphemes as the building blocks of every expression, and the rest is syntax all the way down.

For visual word processing experiments, this means that every string of characters conventionally seen as a word will have a complex underlying structure. What happens with this structure in the process of lexical recognition is a question best answered by the \textit{Obligatory Decomposition Model} (\citeauthor{Taft+1979} \citeyear{Taft+1979}, \citeauthor{Taft+2004} \citeyear{Taft+2004}): according to this model, every morphologically complex word undergoes a process of lexical recognition involving the steps of full decomposition, morpheme lookup, and recombination. 

While \citeauthor{Taft+2004} (\citeyear{Taft+2004}) argues that this model applies only to derivations, there is ample evidence from recent psycholinguistic and neurolinguistic experiments within the framework of DM for even irregular inflectional forms such as \textit{break} --- \textit{broke} being processed the same way (\citeauthor{Stockall+Marantz2006} \citeyear{Stockall+Marantz2006}; \citeauthor{Fruchter+etal+2013} \citeyear{Fruchter+etal+2013} and \citeauthor{Fruchter+Marantz+2015} \citeyear{Fruchter+Marantz+2015}). In other words, virtually every complex word is first decomposed into the constituent morphemes it consists of based on the distributional morpho-orthographic cues (\cite{Rastle+etal+2004}). Afterwards, every morpheme is looked up in the theoretical equivalent of the lexicon and its lexical and grammatical information is accessed, after which every constituent is recombined again within the structure and finally assessed for well-formedness along structural and semantic criteria. Only then is the decision regarding its status as a word is finally made. Naturally, every part of this process comes at a cognitive cost: the more complex a word, the more morphemes need to be retrieved, and the more nodes in the structure have to be spelled out again in order to reconstitute the initial input. This is reflected in the time it takes to recognize a complex word as such, and higher levels of internal complexity have been associated with higher reaction times (\cite{Stockall+Marantz2006}).

Assuming the \textit{Obligatory Decomposition Model} as the working hypothesis for visual word processing, we can operationalise the difference in structural complexity of the Dutch diminutive in terms of the following predictions: since wordforms featuring the derivational diminutive include an extra lexical projection in their structure, they effectively require one more morpheme in their makeup compared to their inflected counterparts. In addition, both the derived diminutives and \textit{diminutiva tantum} are proposed to pattern together with regards to reaction times: based on the effects observed in \citeauthor{Taft+1979} (\citeyear{Taft+1979}) and \citeauthor{Rastle+etal+2004} (\citeyear{Rastle+etal+2004}), even seemingly complex words like \textit{diminutiva tantum} would be decomposed and their (bound) roots accessed, implying the same structural analysis as the derived diminutives with freely occurring roots. Both types are additionally more idiosyncratic in meaning compared to the inflectional diminutives and should therefore require more time to process, given that their meaning can neither arise on purely compositional grounds not is represented in a lexicon as such. Therefore, they should elicit longer reaction times on average, as the process of word recognition becomes more costly with rising structural and semantic complexity.